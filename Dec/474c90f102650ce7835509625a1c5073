By all accounts, retired Army Gen. Lloyd Austin, just confirmed by the Senate to lead the U.S. Defense Department, is eminently qualified to be secretary of defense. A man who achieved the rank of four-star general and succeeded at every turn during his 40-year career, Austin displayed valor and courage while serving the country for nearly half a century. Ironically, though, Austin’s lengthy military career created a sticking point in his confirmation process. The law requires a service member to be out of uniform for at least seven years before assuming the civilian role of secretary of defense. Austin left the Army just over four years ago, which made him technically ineligible for the post. Congress waived the waiting period before confirming him, something it had previously done only twice since 1947, most recently in 2017. Austin’s selection is historic. He is the first African American to lead the nation’s military establishment, a step toward broadening the Pentagon’s largely white male leadership ranks. Yet the fact that Austin’s extensive military experience briefly clouded his prospects raises the question of why the seven-year delay exists in the first place. The formal legal delay dates from the end of World War II, but the concept behind it harks back to the nation’s origins and lies at the heart of the American military tradition. The founders had personally experienced an empire’s use of a standing army and therefore viewed large military forces as the hallmark of authoritarianism and an inherent threat to democracy. They believed that generals’ influence over how armies are used must always be subordinate to those officials directly accountable to the people. Samuel Adams wrote in 1768 that “even when there is a necessity of the military power, within a land, a wise and prudent people will always have a watchful and jealous eye over it.” In 1776, the Virginia Declaration of Rights asserted that “in all cases, the military should be under strict subordination to, and governed by, civil power.” That document became an inspiration for the Declaration of Independence and, later, a model for the Bill of Rights. When it came to the Constitution, the founders specifically prescribed civilian control over the military by assigning the president the role of commander-in-chief while giving Congress the power to set the military’s rules and budget. In the wake of World War II, Congress worried that the American public had increasingly fallen under the spell of charismatic generals like Douglas MacArthur, buying into the argument that greater autonomy should be given to the heroic captains of battle. As MacArthur saw things, the prerogative of proven warriors should not be checked by civilians who know nothing of war. Congress disagreed and created the waiting period to limit career military officials’ eligibility to run the newly created Department of Defense. A 10-year gap in service – later shortened to seven years – would allow a general’s “star to fade” to an acceptable level, reducing their influence over the public. Many defense secretaries have been veterans but not career soldiers – like Chuck Hagel, who had been a soldier in the Vietnam War in 1967 and 1968, decades before he led the Pentagon for President Barack Obama from 2013 to 2015. Others have been scholars, politicians and leaders of business or industry, like James Forrestal, appointed the first defense secretary in 1947, who had worked on Wall Street before joining the government. Their leadership skills and experience were developed at least as much outside the military as within it. As a major in the Army National Guard, I am familiar with the mentality of career military officers. During my nearly 20 years as a military lawyer, I have never heard a senior officer tell a superior he or she couldn’t accomplish a mission. In the mind of a colonel or general, there is literally nothing that cannot be achieved with a well-disciplined group of soldiers, smart tactics and an ample supply of funding and equipment. This can-do attitude is part of the career officer mentality – but so is a certain intolerance for dissenting opinions. The foundational premise of military management is a unity of command and a single voice of authority. Senior officers typically have little patience for opposing views or consensus-building. Diversity of thought is not celebrated; contrarian views are not welcome. [Deep knowledge, daily. Sign up for The Conversation’s newsletter.] As the Supreme Court has observed, “the military is, by necessity, a specialized society separate from civilian society.” It is an institution that has “developed laws and traditions of its own during its long history,” a body where, in the end, the “law is that of obedience.” Retired Gen. George Marshall received the first waiver of the waiting period in 1950. Marshall made a candid observation during the nomination process: “As a second lieutenant, I thought we would never get anywhere in the Army unless a soldier was secretary of war. As I grew a little older and served through some of our military history … I came to the fixed conclusion that he should never be a soldier.” Considered uniquely qualified to oversee U.S. forces in the Korean War, Marshall was eventually confirmed on the condition his tenure would be limited to one year. Congress stated at the time that “no additional appointments of military men to that office shall be approved.” It took nearly 70 years for the second waiver to be granted, to retired Gen. James Mattis in 2017. His confirmation faced early resistance from senators, especially Democrats, because Mattis had left the Marines just four years earlier. In reluctantly voting to confirm Mattis, Sen. Jack Reed, a Rhode Island Democrat on the Senate Armed Services Committee, cautioned that “waiving the law should happen no more than once a generation.” Austin has now become the third recipient of a waiver. He professes to have acquired a civilian mindset since leaving active duty, but the rationale underlying the waiting period remains as vital and relevant as ever. “An Army is not a deliberative body,” the Supreme Court once observed. Giving career members of this body the authority to decide how America’s blood and treasure are spent should be the exception, not the rule. This is an updated version of an article originally published Dec. 17, 2020.